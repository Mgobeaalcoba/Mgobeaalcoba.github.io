<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/images/consulting-logo-dark.png" fetchPriority="high"/><link rel="stylesheet" href="/_next/static/css/a10184582ccec3b3.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-9c394304df224996.js"/><script src="/_next/static/chunks/fd9d1056-412c59b791a861c3.js" async=""></script><script src="/_next/static/chunks/23-8ac259605f7823e6.js" async=""></script><script src="/_next/static/chunks/main-app-46f91be91379a7c8.js" async=""></script><script src="/_next/static/chunks/223-af2330a6fb348319.js" async=""></script><script src="/_next/static/chunks/app/layout-2e2d20e3b16767e4.js" async=""></script><script src="/_next/static/chunks/411-492359e6f17b6d31.js" async=""></script><script src="/_next/static/chunks/878-a29680cbe3281057.js" async=""></script><script src="/_next/static/chunks/app/not-found-117f1fccc739576a.js" async=""></script><script src="/_next/static/chunks/324-b7d1f52fa65230ef.js" async=""></script><script src="/_next/static/chunks/177-847c212eb0a8ea49.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-DG0SLT5RY3" as="script"/><title>Embeddings explicados simple: La magia detrás de GenAI | Mariano Gobea Alcoba</title><meta name="description" content="Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI."/><link rel="author" href="https://mgobeaalcoba.github.io"/><meta name="author" content="Mariano Gobea Alcoba"/><meta name="keywords" content="data analytics,technical leader,mercadolibre,mariano gobea alcoba,consultoría tecnológica,automatización,business intelligence,python,machine learning,data engineer,buenos aires"/><meta name="creator" content="Mariano Gobea Alcoba"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow"/><meta property="og:title" content="Embeddings explicados simple: La magia detrás de GenAI"/><meta property="og:description" content="Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-06-21"/><meta property="article:author" content="Mariano Gobea Alcoba"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@MGobeaAlcoba"/><meta name="twitter:creator" content="@MGobeaAlcoba"/><meta name="twitter:title" content="Embeddings explicados simple: La magia detrás de GenAI"/><meta name="twitter:description" content="Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI."/><link rel="icon" href="/icon.png?eced7bd6d4cd2c8e" type="image/png" sizes="512x512"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><meta name="theme-color" content="#111827"/><meta name="geo.region" content="AR-C"/><meta name="geo.placename" content="Buenos Aires"/><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&amp;family=JetBrains+Mono:wght@400;500&amp;display=swap" rel="stylesheet"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><link rel="stylesheet" href="https://assets.calendly.com/assets/external/widget.css"/><div class="bg-black min-h-screen"><main class="min-h-screen"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent "><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="flex items-center group" href="/"><img alt="MGA Tech Consulting" fetchPriority="high" width="160" height="67" decoding="async" data-nimg="1" class="h-9 w-auto object-contain" style="color:transparent" src="/images/consulting-logo-dark.png"/></a><div class="hidden md:flex items-center gap-6"><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/">Portfolio</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/consulting/">Consultoría</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-sky-400" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/recursos/">Recursos</a></div><div class="flex items-center gap-2"><div class="hidden sm:flex items-center gap-1 glass rounded-lg px-2 py-1"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe text-gray-400" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg><button class="text-xs px-1.5 py-0.5 rounded transition-colors text-sky-400 font-bold">ES</button><span class="text-gray-600">|</span><button class="text-xs px-1.5 py-0.5 rounded transition-colors text-gray-400 hover:text-gray-200">EN</button></div><button class="glass p-2 rounded-lg text-gray-400 hover:text-sky-400 transition-colors" title="Theme: dark"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-moon" aria-hidden="true"><path d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"></path></svg></button><button class="md:hidden glass p-2 rounded-lg text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></div></div></div></nav><article class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 pt-28 pb-20"><a class="inline-flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors mb-8" href="/blog/"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Volver al blog</a><header class="mb-10"><div class="flex flex-wrap items-center gap-3 mb-4"><span class="text-xs px-2 py-0.5 bg-sky-500/20 text-sky-300 border border-sky-500/30 rounded-full font-medium">automation</span><span class="text-xs px-2 py-0.5 bg-yellow-500/20 text-yellow-300 border border-yellow-500/30 rounded-full">⭐ Featured</span></div><h1 class="text-3xl sm:text-4xl font-black text-gray-100 leading-tight mb-4">Embeddings explicados simple: La magia detrás de GenAI</h1><p class="text-gray-400 text-lg leading-relaxed mb-6">Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI.</p><div class="flex flex-wrap items-center gap-4 text-sm text-gray-500 pb-6 border-b border-white/10"><span class="flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>20 de junio de 2026</span><span class="flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M12 6v6l4 2"></path></svg>10 min</span><div class="flex gap-2 flex-wrap"><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>embeddings</span><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>genai</span><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>ml</span></div></div></header><div class="prose prose-invert prose-sky max-w-none prose-headings:text-gray-100 prose-headings:font-bold prose-p:text-gray-300 prose-p:leading-relaxed prose-a:text-sky-400 prose-a:no-underline hover:prose-a:underline prose-code:text-sky-300 prose-code:bg-sky-500/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:before:content-none prose-code:after:content-none prose-pre:bg-gray-900 prose-pre:border prose-pre:border-white/10 prose-pre:rounded-xl prose-blockquote:border-l-sky-500 prose-blockquote:text-gray-400 prose-strong:text-gray-100 prose-li:text-gray-300 prose-hr:border-white/10 prose-table:border-collapse prose-thead:bg-gray-800/60 prose-th:text-gray-200 prose-th:font-semibold prose-th:border prose-th:border-white/10 prose-th:px-4 prose-th:py-2 prose-td:text-gray-300 prose-td:border prose-td:border-white/10 prose-td:px-4 prose-td:py-2"><h2>¿Qué Son Embeddings?</h2>
<p><strong>Vectores numéricos que representan el significado de un texto.</strong></p>
<p>Ejemplo:</p>
<ul>
<li>"perro" → [0.2, -0.5, 0.8, ..., 0.1] (1536 números)</li>
<li>"gato" → [0.18, -0.48, 0.75, ..., 0.09]</li>
</ul>
<p>Palabras similares tienen vectores similares.</p>
<h2>Por Qué Importan</h2>
<p>Computadoras no entienden texto. <strong>Entienden números.</strong></p>
<p>Embeddings convierten texto → números de forma que <strong>preserve el significado</strong>.</p>
<h2>Código: Tu Primer Embedding</h2>
<pre><code class="language-python">import openai

text = "Python es un lenguaje de programación"

response = openai.Embedding.create(
    input=text,
    model="text-embedding-3-small"
)

embedding = response['data'][0]['embedding']

print(f"Dimensiones: {len(embedding)}")  # 1536
print(f"Primeros 5 valores: {embedding[:5]}")
# [0.023, -0.154, 0.892, 0.421, -0.667]
</code></pre>
<h2>Similitud Semántica</h2>
<p>Dos textos similares = embeddings cercanos.</p>
<pre><code class="language-python">import numpy as np

def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# Embeddings
emb_python = get_embedding("Python es un lenguaje")
emb_java = get_embedding("Java es un lenguaje")
emb_pizza = get_embedding("Me gusta la pizza")

# Similitudes
print(cosine_similarity(emb_python, emb_java))   # 0.87 (muy similar)
print(cosine_similarity(emb_python, emb_pizza))  # 0.12 (no relacionados)
</code></pre>
<h2>Aplicación #1: Search Semántico</h2>
<pre><code class="language-python"># Indexar documentos
docs = [
    "Cómo optimizar queries en BigQuery",
    "Python para automatizar tareas",
    "Guía de Docker para data engineers"
]

embeddings_docs = [get_embedding(doc) for doc in docs]

# Query del usuario
query = "mejorar performance de SQL"
emb_query = get_embedding(query)

# Encontrar doc más similar
similarities = [cosine_similarity(emb_query, emb_doc) for emb_doc in embeddings_docs]
best_match_idx = np.argmax(similarities)

print(f"Mejor match: {docs[best_match_idx]}")
# Output: "Cómo optimizar queries en BigQuery"
</code></pre>
<p><strong>Magia:</strong> Encontró "BigQuery" aunque busqué "SQL".</p>
<h2>Aplicación #2: RAG (Retrieval Augmented Generation)</h2>
<pre><code class="language-python">def ask_with_context(question, knowledge_base):
    # 1. Buscar docs relevantes
    emb_q = get_embedding(question)
    similarities = [cosine_similarity(emb_q, emb_doc) 
                    for emb_doc in knowledge_base_embeddings]
    
    # Top 3 docs
    top_3_idx = np.argsort(similarities)[-3:]
    context = "\n".join([knowledge_base[i] for i in top_3_idx])
    
    # 2. LLM con contexto
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": f"Contexto:\n{context}"},
            {"role": "user", "content": question}
        ]
    )
    
    return response.choices[0].message.content

# Usar
answer = ask_with_context(
    "¿Cómo optimizar BigQuery?",
    knowledge_base=mis_documentos
)
</code></pre>
<h2>Aplicación #3: Clasificación de Texto</h2>
<pre><code class="language-python"># Embeddings de categorías
categorias = {
    "soporte": get_embedding("problema técnico, error, no funciona, ayuda"),
    "ventas": get_embedding("comprar, precio, producto, cotización"),
    "rrhh": get_embedding("empleo, trabajo, vacante, sueldo")
}

# Clasificar email
email_text = "Hola, no puedo iniciar sesión en el sistema"
emb_email = get_embedding(email_text)

# Encontrar categoría más similar
scores = {cat: cosine_similarity(emb_email, emb_cat) 
          for cat, emb_cat in categorias.items()}

categoria_final = max(scores, key=scores.get)
print(f"Categoría: {categoria_final}")  # "soporte"
</code></pre>
<h2>Modelos de Embeddings en 2026</h2>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Dimensiones</th>
<th>Costo/1M tokens</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>text-embedding-3-small</strong></td>
<td>1536</td>
<td>$0.02</td>
<td>General purpose</td>
</tr>
<tr>
<td><strong>text-embedding-3-large</strong></td>
<td>3072</td>
<td>$0.13</td>
<td>Max quality</td>
</tr>
<tr>
<td><strong>ada-002</strong> (old)</td>
<td>1536</td>
<td>$0.10</td>
<td>Legacy</td>
</tr>
</tbody>
</table>
<p><strong>Recomendación:</strong> text-embedding-3-small (mejor calidad/precio).</p>
<h2>Embeddings Multilingües</h2>
<pre><code class="language-python"># Mismo embedding model funciona en múltiples idiomas
emb_es = get_embedding("Hola, cómo estás")
emb_en = get_embedding("Hello, how are you")

similarity = cosine_similarity(emb_es, emb_en)
print(similarity)  # ~0.85 (alta similitud cross-language!)
</code></pre>
<h2>Limitaciones</h2>
<h3>1. Contexto Limitado</h3>
<p>Embeddings capturan significado de <strong>~8000 tokens máximo</strong>.</p>
<p>Para documentos largos: <strong>chunking</strong>.</p>
<h3>2. No Es Perfecto</h3>
<pre><code class="language-python"># Estas dos tienen embeddings similares:
"Amo Python"
"Odio Python"

# Embeddings capturan TÓPICO, no necesariamente sentimiento
</code></pre>
<h3>3. Costo</h3>
<p>1M tokens de embeddings = $0.02</p>
<p>Para millones de docs, el costo escala.</p>
<h2>Tips de Producción</h2>
<h3>1. Cache Embeddings</h3>
<pre><code class="language-python">import hashlib
import pickle

def get_embedding_cached(text, cache_dir='embeddings_cache'):
    # Hash del texto
    text_hash = hashlib.md5(text.encode()).hexdigest()
    cache_path = f"{cache_dir}/{text_hash}.pkl"
    
    # Check cache
    if os.path.exists(cache_path):
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    
    # Generate embedding
    embedding = get_embedding(text)
    
    # Save to cache
    os.makedirs(cache_dir, exist_ok=True)
    with open(cache_path, 'wb') as f:
        pickle.dump(embedding, f)
    
    return embedding
</code></pre>
<h3>2. Batch Processing</h3>
<pre><code class="language-python"># ✅ Procesar en batch (más eficiente)
texts = ["texto1", "texto2", ..., "texto100"]

response = openai.Embedding.create(
    input=texts,  # Lista de textos
    model="text-embedding-3-small"
)

embeddings = [item['embedding'] for item in response['data']]
</code></pre>
<h2>Conclusión</h2>
<p>Embeddings son la <strong>tecnología fundamental</strong> detrás de GenAI moderno.</p>
<p>Entenderlos te permite construir:</p>
<ul>
<li>Search semántico</li>
<li>RAG systems</li>
<li>Clasificadores de texto</li>
<li>Recomendadores</li>
</ul>
<p>No es magia: <strong>es matemática bien aplicada</strong>.</p>
<hr>
<p><em>¿Implementando search semántico? <a href="https://mgobeaalcoba.github.io/blog-post.html?slug=vector-databases-guia-practica">Vector DB post</a></em></p>
</div><div class="mt-12 pt-8 border-t border-white/10"><p class="text-gray-400 text-sm mb-4">Escrito por <span class="text-sky-400 font-medium">Mariano Gobea Alcoba</span></p><div class="flex gap-4"><a class="text-sm text-sky-400 hover:text-sky-300 transition-colors" href="/blog/">← Otros artículos</a><a class="text-sm text-sky-400 hover:text-sky-300 transition-colors" href="/consulting/">Consultoría →</a></div></div></article><footer class="glass border-t border-white/10 mt-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div class="grid grid-cols-1 md:grid-cols-4 gap-8"><div class="md:col-span-1"><a class="block mb-4" href="/"><img alt="MGA Tech Consulting" loading="lazy" width="180" height="75" decoding="async" data-nimg="1" class="h-10 w-auto object-contain" style="color:transparent" src="/images/consulting-logo-dark.png"/></a><p class="text-gray-400 text-sm leading-relaxed">Data &amp; Analytics Technical Leader at MercadoLibre.<br/>Buenos Aires, Argentina.</p></div><div><h4 class="text-gray-200 font-semibold mb-3">Navegación</h4><ul class="space-y-2 text-sm"><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/">Portfolio / CV</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/consulting/">Consultoría</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/blog/">Blog</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/recursos/">Recursos</a></li></ul></div><div><h4 class="text-gray-200 font-semibold mb-3">Contacto</h4><div class="flex flex-col gap-2"><a href="https://www.linkedin.com/in/mariano-gobea-alcoba/" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg>LinkedIn</a><a href="https://github.com/Mgobeaalcoba" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>GitHub</a><a href="https://twitter.com/MGobeaAlcoba" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-twitter" aria-hidden="true"><path d="M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z"></path></svg>Twitter/X</a><a href="mailto:gobeamariano@gmail.com" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg>gobeamariano@gmail.com</a></div></div><div><h4 class="text-gray-200 font-semibold mb-3">Tecnología</h4><div class="flex flex-col gap-1 text-xs text-gray-500"><span>Next.js 14 · TypeScript</span><span>Tailwind CSS · Framer Motion</span><span>GitHub Pages · GA4</span><span class="mt-2 text-gray-600">© 2026 Mariano Gobea Alcoba</span></div></div></div><div class="mt-8 pt-8 border-t border-white/10 flex flex-col sm:flex-row items-center justify-between gap-4"><p class="text-gray-500 text-sm flex items-center gap-1">Diseñado con<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart text-red-400" aria-hidden="true"><path d="M2 9.5a5.5 5.5 0 0 1 9.591-3.676.56.56 0 0 0 .818 0A5.49 5.49 0 0 1 22 9.5c0 2.29-1.5 4-3 5.5l-5.492 5.313a2 2 0 0 1-3 .019L5 15c-1.5-1.5-3-3.2-3-5.5"></path></svg> <!-- -->en Buenos Aires<!-- --> · 2026</p><div class="flex items-center gap-3 text-xs text-gray-600"><a href="https://github.com/Mgobeaalcoba" target="_blank" rel="noopener noreferrer" class="hover:text-sky-400 transition-colors">GitHub</a><span>·</span><a href="https://www.linkedin.com/in/mariano-gobea-alcoba/" target="_blank" rel="noopener noreferrer" class="hover:text-sky-400 transition-colors">LinkedIn</a><span>·</span><a href="mailto:gobeamariano@gmail.com" class="hover:text-sky-400 transition-colors">Email</a></div></div></div></footer></main></div><script src="/_next/static/chunks/webpack-9c394304df224996.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/a10184582ccec3b3.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[95751,[],\"\"]\n5:I[39275,[],\"\"]\n7:I[61343,[],\"\"]\n8:I[84080,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-2e2d20e3b16767e4.js\"],\"\"]\n9:I[45064,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-2e2d20e3b16767e4.js\"],\"ThemeProvider\"]\na:I[78155,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-2e2d20e3b16767e4.js\"],\"LanguageProvider\"]\nb:I[74541,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-2e2d20e3b16767e4.js\"],\"default\"]\nc:I[78458,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"878\",\"static/chunks/878-a29680cbe3281057.js\",\"160\",\"static/chunks/app/not-found-117f1fccc739576a.js\"],\"default\"]\ne:I[76130,[],\"\"]\n6:[\"slug\",\"embeddings-explicados-simple\",\"d\"]\nf:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/a10184582ccec3b3.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"vejvoQ79za35W4NIZt_tz\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/embeddings-explicados-simple/\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"embeddings-explicados-simple\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"embeddings-explicados-simple\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"embeddings-explicados-simple\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"es\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"href\":\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900\u0026family=JetBrains+Mono:wght@400;500\u0026display=swap\",\"rel\":\"stylesheet\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#111827\"}],[\"$\",\"meta\",null,{\"name\":\"geo.region\",\"content\":\"AR-C\"}],[\"$\",\"meta\",null,{\"name\":\"geo.placename\",\"content\":\"Buenos Aires\"}]]}],[\"$\",\"body\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://assets.calendly.com/assets/external/widget.css\"}],[\"$\",\"$L8\",null,{\"src\":\"https://assets.calendly.com/assets/external/widget.js\",\"strategy\":\"lazyOnload\"}],[\"$\",\"$L8\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-DG0SLT5RY3\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$L8\",null,{\"id\":\"ga4-init\",\"strategy\":\"afterInteractive\",\"children\":\"\\n            window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-DG0SLT5RY3', {\\n              page_path: window.location.pathname,\\n              site_section: 'cv',\\n              client_name: 'Mariano Gobea Alcoba',\\n            });\\n          \"}],[\"$\",\"$L9\",null,{\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$Lc\",null,{}],\"notFoundStyles\":[],\"styles\":null}]}]}]}]]}]]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Ld\"],\"globalErrorComponent\":\"$e\",\"missingSlots\":\"$Wf\"}]]\n"])</script><script>self.__next_f.push([1,"10:I[53655,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-847c212eb0a8ea49.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n11:I[61592,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-847c212eb0a8ea49.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n12:I[231,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-847c212eb0a8ea49.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"\"]\n14:I[65190,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-847c212eb0a8ea49.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n13:T1a90,"])</script><script>self.__next_f.push([1,"\u003ch2\u003e¿Qué Son Embeddings?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eVectores numéricos que representan el significado de un texto.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eEjemplo:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\"perro\" → [0.2, -0.5, 0.8, ..., 0.1] (1536 números)\u003c/li\u003e\n\u003cli\u003e\"gato\" → [0.18, -0.48, 0.75, ..., 0.09]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePalabras similares tienen vectores similares.\u003c/p\u003e\n\u003ch2\u003ePor Qué Importan\u003c/h2\u003e\n\u003cp\u003eComputadoras no entienden texto. \u003cstrong\u003eEntienden números.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eEmbeddings convierten texto → números de forma que \u003cstrong\u003epreserve el significado\u003c/strong\u003e.\u003c/p\u003e\n\u003ch2\u003eCódigo: Tu Primer Embedding\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport openai\n\ntext = \"Python es un lenguaje de programación\"\n\nresponse = openai.Embedding.create(\n    input=text,\n    model=\"text-embedding-3-small\"\n)\n\nembedding = response['data'][0]['embedding']\n\nprint(f\"Dimensiones: {len(embedding)}\")  # 1536\nprint(f\"Primeros 5 valores: {embedding[:5]}\")\n# [0.023, -0.154, 0.892, 0.421, -0.667]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eSimilitud Semántica\u003c/h2\u003e\n\u003cp\u003eDos textos similares = embeddings cercanos.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport numpy as np\n\ndef cosine_similarity(vec1, vec2):\n    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n\n# Embeddings\nemb_python = get_embedding(\"Python es un lenguaje\")\nemb_java = get_embedding(\"Java es un lenguaje\")\nemb_pizza = get_embedding(\"Me gusta la pizza\")\n\n# Similitudes\nprint(cosine_similarity(emb_python, emb_java))   # 0.87 (muy similar)\nprint(cosine_similarity(emb_python, emb_pizza))  # 0.12 (no relacionados)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eAplicación #1: Search Semántico\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Indexar documentos\ndocs = [\n    \"Cómo optimizar queries en BigQuery\",\n    \"Python para automatizar tareas\",\n    \"Guía de Docker para data engineers\"\n]\n\nembeddings_docs = [get_embedding(doc) for doc in docs]\n\n# Query del usuario\nquery = \"mejorar performance de SQL\"\nemb_query = get_embedding(query)\n\n# Encontrar doc más similar\nsimilarities = [cosine_similarity(emb_query, emb_doc) for emb_doc in embeddings_docs]\nbest_match_idx = np.argmax(similarities)\n\nprint(f\"Mejor match: {docs[best_match_idx]}\")\n# Output: \"Cómo optimizar queries en BigQuery\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eMagia:\u003c/strong\u003e Encontró \"BigQuery\" aunque busqué \"SQL\".\u003c/p\u003e\n\u003ch2\u003eAplicación #2: RAG (Retrieval Augmented Generation)\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef ask_with_context(question, knowledge_base):\n    # 1. Buscar docs relevantes\n    emb_q = get_embedding(question)\n    similarities = [cosine_similarity(emb_q, emb_doc) \n                    for emb_doc in knowledge_base_embeddings]\n    \n    # Top 3 docs\n    top_3_idx = np.argsort(similarities)[-3:]\n    context = \"\\n\".join([knowledge_base[i] for i in top_3_idx])\n    \n    # 2. LLM con contexto\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4\",\n        messages=[\n            {\"role\": \"system\", \"content\": f\"Contexto:\\n{context}\"},\n            {\"role\": \"user\", \"content\": question}\n        ]\n    )\n    \n    return response.choices[0].message.content\n\n# Usar\nanswer = ask_with_context(\n    \"¿Cómo optimizar BigQuery?\",\n    knowledge_base=mis_documentos\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eAplicación #3: Clasificación de Texto\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Embeddings de categorías\ncategorias = {\n    \"soporte\": get_embedding(\"problema técnico, error, no funciona, ayuda\"),\n    \"ventas\": get_embedding(\"comprar, precio, producto, cotización\"),\n    \"rrhh\": get_embedding(\"empleo, trabajo, vacante, sueldo\")\n}\n\n# Clasificar email\nemail_text = \"Hola, no puedo iniciar sesión en el sistema\"\nemb_email = get_embedding(email_text)\n\n# Encontrar categoría más similar\nscores = {cat: cosine_similarity(emb_email, emb_cat) \n          for cat, emb_cat in categorias.items()}\n\ncategoria_final = max(scores, key=scores.get)\nprint(f\"Categoría: {categoria_final}\")  # \"soporte\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eModelos de Embeddings en 2026\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eModelo\u003c/th\u003e\n\u003cth\u003eDimensiones\u003c/th\u003e\n\u003cth\u003eCosto/1M tokens\u003c/th\u003e\n\u003cth\u003eUse Case\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003etext-embedding-3-small\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e1536\u003c/td\u003e\n\u003ctd\u003e$0.02\u003c/td\u003e\n\u003ctd\u003eGeneral purpose\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003etext-embedding-3-large\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e3072\u003c/td\u003e\n\u003ctd\u003e$0.13\u003c/td\u003e\n\u003ctd\u003eMax quality\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cstrong\u003eada-002\u003c/strong\u003e (old)\u003c/td\u003e\n\u003ctd\u003e1536\u003c/td\u003e\n\u003ctd\u003e$0.10\u003c/td\u003e\n\u003ctd\u003eLegacy\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003eRecomendación:\u003c/strong\u003e text-embedding-3-small (mejor calidad/precio).\u003c/p\u003e\n\u003ch2\u003eEmbeddings Multilingües\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Mismo embedding model funciona en múltiples idiomas\nemb_es = get_embedding(\"Hola, cómo estás\")\nemb_en = get_embedding(\"Hello, how are you\")\n\nsimilarity = cosine_similarity(emb_es, emb_en)\nprint(similarity)  # ~0.85 (alta similitud cross-language!)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eLimitaciones\u003c/h2\u003e\n\u003ch3\u003e1. Contexto Limitado\u003c/h3\u003e\n\u003cp\u003eEmbeddings capturan significado de \u003cstrong\u003e~8000 tokens máximo\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003ePara documentos largos: \u003cstrong\u003echunking\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3\u003e2. No Es Perfecto\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Estas dos tienen embeddings similares:\n\"Amo Python\"\n\"Odio Python\"\n\n# Embeddings capturan TÓPICO, no necesariamente sentimiento\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3. Costo\u003c/h3\u003e\n\u003cp\u003e1M tokens de embeddings = $0.02\u003c/p\u003e\n\u003cp\u003ePara millones de docs, el costo escala.\u003c/p\u003e\n\u003ch2\u003eTips de Producción\u003c/h2\u003e\n\u003ch3\u003e1. Cache Embeddings\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport hashlib\nimport pickle\n\ndef get_embedding_cached(text, cache_dir='embeddings_cache'):\n    # Hash del texto\n    text_hash = hashlib.md5(text.encode()).hexdigest()\n    cache_path = f\"{cache_dir}/{text_hash}.pkl\"\n    \n    # Check cache\n    if os.path.exists(cache_path):\n        with open(cache_path, 'rb') as f:\n            return pickle.load(f)\n    \n    # Generate embedding\n    embedding = get_embedding(text)\n    \n    # Save to cache\n    os.makedirs(cache_dir, exist_ok=True)\n    with open(cache_path, 'wb') as f:\n        pickle.dump(embedding, f)\n    \n    return embedding\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e2. Batch Processing\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# ✅ Procesar en batch (más eficiente)\ntexts = [\"texto1\", \"texto2\", ..., \"texto100\"]\n\nresponse = openai.Embedding.create(\n    input=texts,  # Lista de textos\n    model=\"text-embedding-3-small\"\n)\n\nembeddings = [item['embedding'] for item in response['data']]\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eConclusión\u003c/h2\u003e\n\u003cp\u003eEmbeddings son la \u003cstrong\u003etecnología fundamental\u003c/strong\u003e detrás de GenAI moderno.\u003c/p\u003e\n\u003cp\u003eEntenderlos te permite construir:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSearch semántico\u003c/li\u003e\n\u003cli\u003eRAG systems\u003c/li\u003e\n\u003cli\u003eClasificadores de texto\u003c/li\u003e\n\u003cli\u003eRecomendadores\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNo es magia: \u003cstrong\u003ees matemática bien aplicada\u003c/strong\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cem\u003e¿Implementando search semántico? \u003ca href=\"https://mgobeaalcoba.github.io/blog-post.html?slug=vector-databases-guia-practica\"\u003eVector DB post\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"main\",null,{\"className\":\"min-h-screen\",\"children\":[[\"$\",\"$L10\",null,{}],[\"$\",\"$L11\",null,{}],[\"$\",\"article\",null,{\"className\":\"max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 pt-28 pb-20\",\"children\":[[\"$\",\"$L12\",null,{\"href\":\"/blog/\",\"className\":\"inline-flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors mb-8\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],\"Volver al blog\"]}],[\"$\",\"header\",null,{\"className\":\"mb-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 mb-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-xs px-2 py-0.5 bg-sky-500/20 text-sky-300 border border-sky-500/30 rounded-full font-medium\",\"children\":\"automation\"}],[\"$\",\"span\",null,{\"className\":\"text-xs px-2 py-0.5 bg-yellow-500/20 text-yellow-300 border border-yellow-500/30 rounded-full\",\"children\":\"⭐ Featured\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-3xl sm:text-4xl font-black text-gray-100 leading-tight mb-4\",\"children\":\"Embeddings explicados simple: La magia detrás de GenAI\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-400 text-lg leading-relaxed mb-6\",\"children\":\"Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-4 text-sm text-gray-500 pb-6 border-b border-white/10\",\"children\":[[\"$\",\"span\",null,{\"className\":\"flex items-center gap-1.5\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-calendar\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1cmpym\",{\"d\":\"M8 2v4\"}],[\"$\",\"path\",\"4m81vk\",{\"d\":\"M16 2v4\"}],[\"$\",\"rect\",\"1hopcy\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"8toen8\",{\"d\":\"M3 10h18\"}],\"$undefined\"]}],\"20 de junio de 2026\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center gap-1.5\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-clock\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"mmk7yg\",{\"d\":\"M12 6v6l4 2\"}],\"$undefined\"]}],\"10 min\"]}],[\"$\",\"div\",null,{\"className\":\"flex gap-2 flex-wrap\",\"children\":[[\"$\",\"span\",\"embeddings\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"embeddings\"]}],[\"$\",\"span\",\"genai\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"genai\"]}],[\"$\",\"span\",\"ml\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"ml\"]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"prose prose-invert prose-sky max-w-none prose-headings:text-gray-100 prose-headings:font-bold prose-p:text-gray-300 prose-p:leading-relaxed prose-a:text-sky-400 prose-a:no-underline hover:prose-a:underline prose-code:text-sky-300 prose-code:bg-sky-500/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:before:content-none prose-code:after:content-none prose-pre:bg-gray-900 prose-pre:border prose-pre:border-white/10 prose-pre:rounded-xl prose-blockquote:border-l-sky-500 prose-blockquote:text-gray-400 prose-strong:text-gray-100 prose-li:text-gray-300 prose-hr:border-white/10 prose-table:border-collapse prose-thead:bg-gray-800/60 prose-th:text-gray-200 prose-th:font-semibold prose-th:border prose-th:border-white/10 prose-th:px-4 prose-th:py-2 prose-td:text-gray-300 prose-td:border prose-td:border-white/10 prose-td:px-4 prose-td:py-2\",\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}],[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-white/10\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-gray-400 text-sm mb-4\",\"children\":[\"Escrito por \",[\"$\",\"span\",null,{\"className\":\"text-sky-400 font-medium\",\"children\":\"Mariano Gobea Alcoba\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\",\"children\":[[\"$\",\"$L12\",null,{\"href\":\"/blog/\",\"className\":\"text-sm text-sky-400 hover:text-sky-300 transition-colors\",\"children\":\"← Otros artículos\"}],[\"$\",\"$L12\",null,{\"href\":\"/consulting/\",\"className\":\"text-sm text-sky-400 hover:text-sky-300 transition-colors\",\"children\":\"Consultoría →\"}]]}]]}]]}],[\"$\",\"$L14\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Embeddings explicados simple: La magia detrás de GenAI | Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"author\",\"href\":\"https://mgobeaalcoba.github.io\"}],[\"$\",\"meta\",\"5\",{\"name\":\"author\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"data analytics,technical leader,mercadolibre,mariano gobea alcoba,consultoría tecnológica,automatización,business intelligence,python,machine learning,data engineer,buenos aires\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"Embeddings explicados simple: La magia detrás de GenAI\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"13\",{\"property\":\"article:published_time\",\"content\":\"2026-06-21\"}],[\"$\",\"meta\",\"14\",{\"property\":\"article:author\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:site\",\"content\":\"@MGobeaAlcoba\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:creator\",\"content\":\"@MGobeaAlcoba\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"Embeddings explicados simple: La magia detrás de GenAI\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"Qué son embeddings, cómo funcionan y por qué son la tecnología clave detrás de GenAI.\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/icon.png?eced7bd6d4cd2c8e\",\"type\":\"image/png\",\"sizes\":\"512x512\"}]]\n3:null\n"])</script></body></html>