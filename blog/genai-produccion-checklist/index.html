<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/images/consulting-logo-dark.png" fetchPriority="high"/><link rel="stylesheet" href="/_next/static/css/2aa5050433ce7d19.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-9c394304df224996.js"/><script src="/_next/static/chunks/fd9d1056-412c59b791a861c3.js" async=""></script><script src="/_next/static/chunks/23-8ac259605f7823e6.js" async=""></script><script src="/_next/static/chunks/main-app-46f91be91379a7c8.js" async=""></script><script src="/_next/static/chunks/223-af2330a6fb348319.js" async=""></script><script src="/_next/static/chunks/app/layout-d6f26fcc1963b964.js" async=""></script><script src="/_next/static/chunks/411-492359e6f17b6d31.js" async=""></script><script src="/_next/static/chunks/878-a29680cbe3281057.js" async=""></script><script src="/_next/static/chunks/app/not-found-a80cb46b8408a4ea.js" async=""></script><script src="/_next/static/chunks/324-b7d1f52fa65230ef.js" async=""></script><script src="/_next/static/chunks/177-d3f1f7ea96e8e7b0.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-DG0SLT5RY3" as="script"/><title>GenAI en Producción: Checklist de 15 puntos antes de deploy | Mariano Gobea Alcoba</title><meta name="description" content="No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales."/><link rel="author" href="https://mgobeaalcoba.github.io"/><meta name="author" content="Mariano Gobea Alcoba"/><meta name="keywords" content="data analytics,technical leader,mercadolibre,mariano gobea alcoba,consultoría tecnológica,automatización,business intelligence,python,machine learning,data engineer,buenos aires"/><meta name="creator" content="Mariano Gobea Alcoba"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow"/><meta property="og:title" content="GenAI en Producción: Checklist de 15 puntos antes de deploy"/><meta property="og:description" content="No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales."/><meta property="og:type" content="article"/><meta property="article:published_time" content="2026-03-08"/><meta property="article:author" content="Mariano Gobea Alcoba"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@MGobeaAlcoba"/><meta name="twitter:creator" content="@MGobeaAlcoba"/><meta name="twitter:title" content="GenAI en Producción: Checklist de 15 puntos antes de deploy"/><meta name="twitter:description" content="No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales."/><link rel="icon" href="/icon.png?eced7bd6d4cd2c8e" type="image/png" sizes="512x512"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><meta name="theme-color" content="#111827"/><meta name="geo.region" content="AR-C"/><meta name="geo.placename" content="Buenos Aires"/><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&amp;family=JetBrains+Mono:wght@400;500&amp;display=swap" rel="stylesheet"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><link rel="stylesheet" href="https://assets.calendly.com/assets/external/widget.css"/><div class="bg-black min-h-screen"><main class="min-h-screen"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent "><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><a class="flex items-center group" href="/"><img alt="MGA Tech Consulting" fetchPriority="high" width="160" height="67" decoding="async" data-nimg="1" class="h-9 w-auto object-contain" style="color:transparent" src="/images/consulting-logo-dark.png"/></a><div class="hidden md:flex items-center gap-6"><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/">Portfolio</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/consulting/">Consultoría</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-sky-400" href="/blog/">Blog</a><a class="text-sm font-medium transition-colors hover:text-sky-400 text-gray-300" href="/recursos/">Recursos</a></div><div class="flex items-center gap-2"><div class="hidden sm:flex items-center gap-1 glass rounded-lg px-2 py-1"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe text-gray-400" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg><button class="text-xs px-1.5 py-0.5 rounded transition-colors text-sky-400 font-bold">ES</button><span class="text-gray-600">|</span><button class="text-xs px-1.5 py-0.5 rounded transition-colors text-gray-400 hover:text-gray-200">EN</button></div><button class="glass p-2 rounded-lg text-gray-400 hover:text-sky-400 transition-colors" title="Theme: dark"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-moon" aria-hidden="true"><path d="M20.985 12.486a9 9 0 1 1-9.473-9.472c.405-.022.617.46.402.803a6 6 0 0 0 8.268 8.268c.344-.215.825-.004.803.401"></path></svg></button><button class="md:hidden glass p-2 rounded-lg text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></div></div></div></nav><article class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 pt-28 pb-20"><a class="inline-flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors mb-8" href="/blog/"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Volver al blog</a><header class="mb-10"><div class="flex flex-wrap items-center gap-3 mb-4"><span class="text-xs px-2 py-0.5 bg-sky-500/20 text-sky-300 border border-sky-500/30 rounded-full font-medium">automation</span><span class="text-xs px-2 py-0.5 bg-yellow-500/20 text-yellow-300 border border-yellow-500/30 rounded-full">⭐ Featured</span></div><h1 class="text-3xl sm:text-4xl font-black text-gray-100 leading-tight mb-4">GenAI en Producción: Checklist de 15 puntos antes de deploy</h1><p class="text-gray-400 text-lg leading-relaxed mb-6">No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales.</p><div class="flex flex-wrap items-center gap-4 text-sm text-gray-500 pb-6 border-b border-white/10"><span class="flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>7 de marzo de 2026</span><span class="flex items-center gap-1.5"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock" aria-hidden="true"><circle cx="12" cy="12" r="10"></circle><path d="M12 6v6l4 2"></path></svg>12 min</span><div class="flex gap-2 flex-wrap"><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>genai</span><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>llm</span><span class="flex items-center gap-1 text-xs text-gray-400"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>production</span></div></div></header><div class="prose prose-invert prose-sky max-w-none prose-headings:text-gray-100 prose-headings:font-bold prose-p:text-gray-300 prose-p:leading-relaxed prose-a:text-sky-400 prose-a:no-underline hover:prose-a:underline prose-code:text-sky-300 prose-code:bg-sky-500/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:before:content-none prose-code:after:content-none prose-pre:bg-gray-900 prose-pre:border prose-pre:border-white/10 prose-pre:rounded-xl prose-blockquote:border-l-sky-500 prose-blockquote:text-gray-400 prose-strong:text-gray-100 prose-li:text-gray-300 prose-hr:border-white/10 prose-table:border-collapse prose-thead:bg-gray-800/60 prose-th:text-gray-200 prose-th:font-semibold prose-th:border prose-th:border-white/10 prose-th:px-4 prose-th:py-2 prose-td:text-gray-300 prose-td:border prose-td:border-white/10 prose-td:px-4 prose-td:py-2"><h2>La Realidad de GenAI en Producción</h2>
<p>Hacer un demo de ChatGPT es fácil. <strong>Llevarlo a producción sin que explote es otra cosa.</strong></p>
<p>He visto proyectos de GenAI fallar por cosas básicas que nadie chequeó antes del deploy.</p>
<h2>Pre-Deploy Checklist</h2>
<h3>1. Rate Limits &#x26; Throttling</h3>
<pre><code class="language-python">from ratelimit import limits, sleep_and_retry

@sleep_and_retry
@limits(calls=50, period=60)  # 50 llamadas por minuto
def call_llm(prompt):
    return openai.ChatCompletion.create(...)
</code></pre>
<p><strong>Por qué:</strong> Las APIs de LLM tienen límites estrictos.</p>
<h3>2. Timeout Configuration</h3>
<pre><code class="language-python">import openai
openai.api_timeout = 30  # 30 segundos máximo

# Con manejo de timeout
try:
    response = openai.ChatCompletion.create(...)
except openai.error.Timeout:
    logger.warning("LLM timeout, usando fallback")
    return fallback_response()
</code></pre>
<h3>3. Cost Monitoring</h3>
<pre><code class="language-python"># Trackear tokens por request
def track_llm_cost(prompt_tokens, completion_tokens, model="gpt-4"):
    costs = {
        "gpt-4": {"input": 0.03, "output": 0.06},  # por 1K tokens
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015}
    }
    
    cost = (prompt_tokens / 1000 * costs[model]["input"] +
            completion_tokens / 1000 * costs[model]["output"])
    
    # Log a metrics system
    metrics.increment('llm_cost_usd', cost)
</code></pre>
<h3>4. Prompt Versioning</h3>
<pre><code class="language-python">PROMPTS = {
    "v1": "Clasifica este email: {text}",
    "v2": "Sos un clasificador experto. Email: {text}. Categorías: [spam, importante, normal]"
}

# Usar versiones para A/B testing
response = call_llm(PROMPTS["v2"].format(text=email_text))
</code></pre>
<h3>5. Output Validation</h3>
<pre><code class="language-python">from pydantic import BaseModel

class LLMResponse(BaseModel):
    category: str
    confidence: float
    reasoning: str

# Validar siempre la respuesta
try:
    validated = LLMResponse.parse_raw(llm_output)
except ValidationError:
    logger.error("LLM returned invalid format")
    return fallback_response()
</code></pre>
<h3>6. Fallback Strategy</h3>
<pre><code class="language-python">def classify_with_fallback(text):
    try:
        # Intentar LLM
        return classify_with_llm(text)
    except Exception as e:
        logger.warning(f"LLM failed: {e}, using rule-based fallback")
        return classify_with_rules(text)  # Fallback tradicional
</code></pre>
<h3>7. Content Moderation</h3>
<pre><code class="language-python">from better_profanity import profanity

def moderate_input(text):
    if profanity.contains_profanity(text):
        raise ValueError("Contenido inapropiado detectado")
    
    if len(text) > 5000:  # Límite razonable
        raise ValueError("Input demasiado largo")
    
    return text
</code></pre>
<h3>8. PII Detection</h3>
<pre><code class="language-python">import re

def remove_pii(text):
    # Email
    text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', text)
    
    # Teléfono argentino
    text = re.sub(r'\+?54\s?9?\s?\d{2,4}\s?\d{4}\s?\d{4}', '[PHONE]', text)
    
    # DNI
    text = re.sub(r'\b\d{8}\b', '[DNI]', text)
    
    return text
</code></pre>
<h3>9. Caching Inteligente</h3>
<pre><code class="language-python">import hashlib
import redis

cache = redis.Redis()

def cached_llm_call(prompt, ttl=3600):
    # Hash del prompt
    cache_key = hashlib.md5(prompt.encode()).hexdigest()
    
    # Check cache
    cached = cache.get(cache_key)
    if cached:
        return cached.decode()
    
    # Call LLM
    response = call_llm(prompt)
    
    # Save to cache
    cache.setex(cache_key, ttl, response)
    
    return response
</code></pre>
<h3>10. Retry Logic con Exponential Backoff</h3>
<pre><code class="language-python">from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_llm_with_retry(prompt):
    return openai.ChatCompletion.create(...)
</code></pre>
<h3>11. Monitoring &#x26; Alerting</h3>
<pre><code class="language-python"># Métricas clave a trackear
metrics = {
    'llm_calls_total': Counter(),
    'llm_errors_total': Counter(),
    'llm_latency_seconds': Histogram(),
    'llm_cost_usd': Gauge(),
    'llm_tokens_used': Counter()
}

def monitored_llm_call(prompt):
    start_time = time.time()
    
    try:
        metrics['llm_calls_total'].inc()
        response = call_llm(prompt)
        metrics['llm_latency_seconds'].observe(time.time() - start_time)
        return response
    except Exception as e:
        metrics['llm_errors_total'].inc()
        raise
</code></pre>
<h3>12. Multimodal Support</h3>
<pre><code class="language-python">def call_llm_with_image(prompt, image_url):
    return openai.ChatCompletion.create(
        model="gpt-4-vision",
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": image_url}
            ]
        }]
    )
</code></pre>
<h3>13. Token Estimation (Antes de llamar)</h3>
<pre><code class="language-python">def estimate_tokens(text):
    # Aproximación: ~4 caracteres por token
    return len(text) // 4

def is_prompt_too_expensive(prompt, max_cost=0.10):
    estimated_tokens = estimate_tokens(prompt)
    estimated_cost = estimated_tokens / 1000 * 0.03  # GPT-4 input
    
    if estimated_cost > max_cost:
        raise ValueError(f"Prompt demasiado costoso: ${estimated_cost:.2f}")
    
    return True
</code></pre>
<h3>14. A/B Testing de Prompts</h3>
<pre><code class="language-python">import random

def get_prompt_variant():
    variants = ["v1", "v2", "v3"]
    return random.choice(variants)

# Log para comparar performance
variant = get_prompt_variant()
response = call_llm(PROMPTS[variant].format(text=input_text))

metrics.record('prompt_variant', variant, {
    'success': response.success,
    'user_satisfaction': calculate_satisfaction(response)
})
</code></pre>
<h3>15. Graceful Degradation</h3>
<pre><code class="language-python">def smart_classification(text):
    # Intentar orden de menor a mayor costo
    
    # 1. Rule-based (gratis, rápido)
    if simple_rules_can_handle(text):
        return rule_based_classify(text)
    
    # 2. Small model (barato)
    try:
        return call_llm(text, model="gpt-3.5-turbo")
    except Exception:
        pass
    
    # 3. Large model (costoso, solo si es necesario)
    try:
        return call_llm(text, model="gpt-4")
    except Exception:
        # 4. Fallback final
        return default_classification()
</code></pre>
<h2>Checklist Completo</h2>
<p>Antes de deploy a producción:</p>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> Rate limits configurados</li>
<li class="task-list-item"><input type="checkbox" disabled> Timeouts definidos</li>
<li class="task-list-item"><input type="checkbox" disabled> Cost monitoring activo</li>
<li class="task-list-item"><input type="checkbox" disabled> Prompts versionados</li>
<li class="task-list-item"><input type="checkbox" disabled> Output validation implementada</li>
<li class="task-list-item"><input type="checkbox" disabled> Fallback strategy funcional</li>
<li class="task-list-item"><input type="checkbox" disabled> Content moderation activa</li>
<li class="task-list-item"><input type="checkbox" disabled> PII detection implementada</li>
<li class="task-list-item"><input type="checkbox" disabled> Cache configurado</li>
<li class="task-list-item"><input type="checkbox" disabled> Retry logic con backoff</li>
<li class="task-list-item"><input type="checkbox" disabled> Monitoring &#x26; alerting activos</li>
<li class="task-list-item"><input type="checkbox" disabled> Multimodal support (si aplica)</li>
<li class="task-list-item"><input type="checkbox" disabled> Token estimation habilitado</li>
<li class="task-list-item"><input type="checkbox" disabled> A/B testing preparado</li>
<li class="task-list-item"><input type="checkbox" disabled> Graceful degradation implementada</li>
</ul>
<h2>Conclusión</h2>
<p>GenAI en producción requiere <strong>ingeniería sólida</strong>, no solo buenas prompts.</p>
<p>Estos 15 puntos son la diferencia entre un POC y un sistema production-ready.</p>
<hr>
<p><em>¿Implementando GenAI? Consultame: <a href="https://mgobeaalcoba.github.io/consulting.html">Servicios de Consultoría</a></em></p>
</div><div class="mt-12 pt-8 border-t border-white/10"><p class="text-gray-400 text-sm mb-4">Escrito por <span class="text-sky-400 font-medium">Mariano Gobea Alcoba</span></p><div class="flex gap-4"><a class="text-sm text-sky-400 hover:text-sky-300 transition-colors" href="/blog/">← Otros artículos</a><a class="text-sm text-sky-400 hover:text-sky-300 transition-colors" href="/consulting/">Consultoría →</a></div></div></article><footer class="glass border-t border-white/10 mt-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div class="grid grid-cols-1 md:grid-cols-4 gap-8"><div class="md:col-span-1"><a class="block mb-4" href="/"><img alt="MGA Tech Consulting" loading="lazy" width="180" height="75" decoding="async" data-nimg="1" class="h-10 w-auto object-contain" style="color:transparent" src="/images/consulting-logo-dark.png"/></a><p class="text-gray-400 text-sm leading-relaxed">Data &amp; Analytics Technical Leader at MercadoLibre.<br/>Buenos Aires, Argentina.</p></div><div><h4 class="text-gray-200 font-semibold mb-3">Navegación</h4><ul class="space-y-2 text-sm"><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/">Portfolio / CV</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/consulting/">Consultoría</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/blog/">Blog</a></li><li><a class="text-gray-400 hover:text-sky-400 transition-colors" href="/recursos/">Recursos</a></li></ul></div><div><h4 class="text-gray-200 font-semibold mb-3">Contacto</h4><div class="flex flex-col gap-2"><a href="https://www.linkedin.com/in/mariano-gobea-alcoba/" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg>LinkedIn</a><a href="https://github.com/Mgobeaalcoba" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>GitHub</a><a href="https://twitter.com/MGobeaAlcoba" target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-twitter" aria-hidden="true"><path d="M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z"></path></svg>Twitter/X</a><a href="mailto:gobeamariano@gmail.com" class="flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg>gobeamariano@gmail.com</a></div></div><div><h4 class="text-gray-200 font-semibold mb-3">Tecnología</h4><div class="flex flex-col gap-1 text-xs text-gray-500"><span>Next.js 14 · TypeScript</span><span>Tailwind CSS · Framer Motion</span><span>GitHub Pages · GA4</span><span class="mt-2 text-gray-600">© 2026 Mariano Gobea Alcoba</span></div></div></div><div class="mt-8 pt-8 border-t border-white/10 flex flex-col sm:flex-row items-center justify-between gap-4"><p class="text-gray-500 text-sm flex items-center gap-1">Diseñado con<!-- --> <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart text-red-400" aria-hidden="true"><path d="M2 9.5a5.5 5.5 0 0 1 9.591-3.676.56.56 0 0 0 .818 0A5.49 5.49 0 0 1 22 9.5c0 2.29-1.5 4-3 5.5l-5.492 5.313a2 2 0 0 1-3 .019L5 15c-1.5-1.5-3-3.2-3-5.5"></path></svg> <!-- -->en Buenos Aires<!-- --> · 2026</p><div class="flex items-center gap-3 text-xs text-gray-600"><a href="https://github.com/Mgobeaalcoba" target="_blank" rel="noopener noreferrer" class="hover:text-sky-400 transition-colors">GitHub</a><span>·</span><a href="https://www.linkedin.com/in/mariano-gobea-alcoba/" target="_blank" rel="noopener noreferrer" class="hover:text-sky-400 transition-colors">LinkedIn</a><span>·</span><a href="mailto:gobeamariano@gmail.com" class="hover:text-sky-400 transition-colors">Email</a></div></div></div></footer></main></div><script src="/_next/static/chunks/webpack-9c394304df224996.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/2aa5050433ce7d19.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[95751,[],\"\"]\n5:I[39275,[],\"\"]\n7:I[61343,[],\"\"]\n8:I[84080,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-d6f26fcc1963b964.js\"],\"\"]\n9:I[45064,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-d6f26fcc1963b964.js\"],\"ThemeProvider\"]\na:I[78155,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-d6f26fcc1963b964.js\"],\"LanguageProvider\"]\nb:I[74541,[\"223\",\"static/chunks/223-af2330a6fb348319.js\",\"185\",\"static/chunks/app/layout-d6f26fcc1963b964.js\"],\"default\"]\nc:I[78458,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"878\",\"static/chunks/878-a29680cbe3281057.js\",\"160\",\"static/chunks/app/not-found-a80cb46b8408a4ea.js\"],\"default\"]\ne:I[76130,[],\"\"]\n6:[\"slug\",\"genai-produccion-checklist\",\"d\"]\nf:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2aa5050433ce7d19.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"z5RjSdat1l3h2szhlUiu8\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/genai-produccion-checklist/\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"genai-produccion-checklist\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"genai-produccion-checklist\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"genai-produccion-checklist\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"$6\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"es\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"href\":\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900\u0026family=JetBrains+Mono:wght@400;500\u0026display=swap\",\"rel\":\"stylesheet\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#111827\"}],[\"$\",\"meta\",null,{\"name\":\"geo.region\",\"content\":\"AR-C\"}],[\"$\",\"meta\",null,{\"name\":\"geo.placename\",\"content\":\"Buenos Aires\"}]]}],[\"$\",\"body\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://assets.calendly.com/assets/external/widget.css\"}],[\"$\",\"$L8\",null,{\"src\":\"https://assets.calendly.com/assets/external/widget.js\",\"strategy\":\"lazyOnload\"}],[\"$\",\"$L8\",null,{\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-DG0SLT5RY3\",\"strategy\":\"afterInteractive\"}],[\"$\",\"$L8\",null,{\"id\":\"ga4-init\",\"strategy\":\"afterInteractive\",\"children\":\"\\n            window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag('js', new Date());\\n            gtag('config', 'G-DG0SLT5RY3', {\\n              page_path: window.location.pathname,\\n              site_section: 'cv',\\n              client_name: 'Mariano Gobea Alcoba',\\n            });\\n          \"}],[\"$\",\"$L9\",null,{\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$Lc\",null,{}],\"notFoundStyles\":[],\"styles\":null}]}]}]}]]}]]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Ld\"],\"globalErrorComponent\":\"$e\",\"missingSlots\":\"$Wf\"}]]\n"])</script><script>self.__next_f.push([1,"10:I[53655,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-d3f1f7ea96e8e7b0.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n11:I[61592,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-d3f1f7ea96e8e7b0.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n12:I[231,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-d3f1f7ea96e8e7b0.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"\"]\n14:I[65190,[\"411\",\"static/chunks/411-492359e6f17b6d31.js\",\"324\",\"static/chunks/324-b7d1f52fa65230ef.js\",\"177\",\"static/chunks/177-d3f1f7ea96e8e7b0.js\",\"308\",\"static/chunks/app/blog/%5Bslug%5D/page-64e8c7352292aee5.js\"],\"default\"]\n13:T21a3,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eLa Realidad de GenAI en Producción\u003c/h2\u003e\n\u003cp\u003eHacer un demo de ChatGPT es fácil. \u003cstrong\u003eLlevarlo a producción sin que explote es otra cosa.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eHe visto proyectos de GenAI fallar por cosas básicas que nadie chequeó antes del deploy.\u003c/p\u003e\n\u003ch2\u003ePre-Deploy Checklist\u003c/h2\u003e\n\u003ch3\u003e1. Rate Limits \u0026#x26; Throttling\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom ratelimit import limits, sleep_and_retry\n\n@sleep_and_retry\n@limits(calls=50, period=60)  # 50 llamadas por minuto\ndef call_llm(prompt):\n    return openai.ChatCompletion.create(...)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003ePor qué:\u003c/strong\u003e Las APIs de LLM tienen límites estrictos.\u003c/p\u003e\n\u003ch3\u003e2. Timeout Configuration\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport openai\nopenai.api_timeout = 30  # 30 segundos máximo\n\n# Con manejo de timeout\ntry:\n    response = openai.ChatCompletion.create(...)\nexcept openai.error.Timeout:\n    logger.warning(\"LLM timeout, usando fallback\")\n    return fallback_response()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e3. Cost Monitoring\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Trackear tokens por request\ndef track_llm_cost(prompt_tokens, completion_tokens, model=\"gpt-4\"):\n    costs = {\n        \"gpt-4\": {\"input\": 0.03, \"output\": 0.06},  # por 1K tokens\n        \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015}\n    }\n    \n    cost = (prompt_tokens / 1000 * costs[model][\"input\"] +\n            completion_tokens / 1000 * costs[model][\"output\"])\n    \n    # Log a metrics system\n    metrics.increment('llm_cost_usd', cost)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e4. Prompt Versioning\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003ePROMPTS = {\n    \"v1\": \"Clasifica este email: {text}\",\n    \"v2\": \"Sos un clasificador experto. Email: {text}. Categorías: [spam, importante, normal]\"\n}\n\n# Usar versiones para A/B testing\nresponse = call_llm(PROMPTS[\"v2\"].format(text=email_text))\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e5. Output Validation\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom pydantic import BaseModel\n\nclass LLMResponse(BaseModel):\n    category: str\n    confidence: float\n    reasoning: str\n\n# Validar siempre la respuesta\ntry:\n    validated = LLMResponse.parse_raw(llm_output)\nexcept ValidationError:\n    logger.error(\"LLM returned invalid format\")\n    return fallback_response()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e6. Fallback Strategy\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef classify_with_fallback(text):\n    try:\n        # Intentar LLM\n        return classify_with_llm(text)\n    except Exception as e:\n        logger.warning(f\"LLM failed: {e}, using rule-based fallback\")\n        return classify_with_rules(text)  # Fallback tradicional\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e7. Content Moderation\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom better_profanity import profanity\n\ndef moderate_input(text):\n    if profanity.contains_profanity(text):\n        raise ValueError(\"Contenido inapropiado detectado\")\n    \n    if len(text) \u003e 5000:  # Límite razonable\n        raise ValueError(\"Input demasiado largo\")\n    \n    return text\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e8. PII Detection\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport re\n\ndef remove_pii(text):\n    # Email\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n    \n    # Teléfono argentino\n    text = re.sub(r'\\+?54\\s?9?\\s?\\d{2,4}\\s?\\d{4}\\s?\\d{4}', '[PHONE]', text)\n    \n    # DNI\n    text = re.sub(r'\\b\\d{8}\\b', '[DNI]', text)\n    \n    return text\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e9. Caching Inteligente\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport hashlib\nimport redis\n\ncache = redis.Redis()\n\ndef cached_llm_call(prompt, ttl=3600):\n    # Hash del prompt\n    cache_key = hashlib.md5(prompt.encode()).hexdigest()\n    \n    # Check cache\n    cached = cache.get(cache_key)\n    if cached:\n        return cached.decode()\n    \n    # Call LLM\n    response = call_llm(prompt)\n    \n    # Save to cache\n    cache.setex(cache_key, ttl, response)\n    \n    return response\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e10. Retry Logic con Exponential Backoff\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003efrom tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10)\n)\ndef call_llm_with_retry(prompt):\n    return openai.ChatCompletion.create(...)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e11. Monitoring \u0026#x26; Alerting\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003e# Métricas clave a trackear\nmetrics = {\n    'llm_calls_total': Counter(),\n    'llm_errors_total': Counter(),\n    'llm_latency_seconds': Histogram(),\n    'llm_cost_usd': Gauge(),\n    'llm_tokens_used': Counter()\n}\n\ndef monitored_llm_call(prompt):\n    start_time = time.time()\n    \n    try:\n        metrics['llm_calls_total'].inc()\n        response = call_llm(prompt)\n        metrics['llm_latency_seconds'].observe(time.time() - start_time)\n        return response\n    except Exception as e:\n        metrics['llm_errors_total'].inc()\n        raise\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e12. Multimodal Support\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef call_llm_with_image(prompt, image_url):\n    return openai.ChatCompletion.create(\n        model=\"gpt-4-vision\",\n        messages=[{\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": prompt},\n                {\"type\": \"image_url\", \"image_url\": image_url}\n            ]\n        }]\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e13. Token Estimation (Antes de llamar)\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef estimate_tokens(text):\n    # Aproximación: ~4 caracteres por token\n    return len(text) // 4\n\ndef is_prompt_too_expensive(prompt, max_cost=0.10):\n    estimated_tokens = estimate_tokens(prompt)\n    estimated_cost = estimated_tokens / 1000 * 0.03  # GPT-4 input\n    \n    if estimated_cost \u003e max_cost:\n        raise ValueError(f\"Prompt demasiado costoso: ${estimated_cost:.2f}\")\n    \n    return True\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e14. A/B Testing de Prompts\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eimport random\n\ndef get_prompt_variant():\n    variants = [\"v1\", \"v2\", \"v3\"]\n    return random.choice(variants)\n\n# Log para comparar performance\nvariant = get_prompt_variant()\nresponse = call_llm(PROMPTS[variant].format(text=input_text))\n\nmetrics.record('prompt_variant', variant, {\n    'success': response.success,\n    'user_satisfaction': calculate_satisfaction(response)\n})\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e15. Graceful Degradation\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003edef smart_classification(text):\n    # Intentar orden de menor a mayor costo\n    \n    # 1. Rule-based (gratis, rápido)\n    if simple_rules_can_handle(text):\n        return rule_based_classify(text)\n    \n    # 2. Small model (barato)\n    try:\n        return call_llm(text, model=\"gpt-3.5-turbo\")\n    except Exception:\n        pass\n    \n    # 3. Large model (costoso, solo si es necesario)\n    try:\n        return call_llm(text, model=\"gpt-4\")\n    except Exception:\n        # 4. Fallback final\n        return default_classification()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eChecklist Completo\u003c/h2\u003e\n\u003cp\u003eAntes de deploy a producción:\u003c/p\u003e\n\u003cul class=\"contains-task-list\"\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Rate limits configurados\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Timeouts definidos\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Cost monitoring activo\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Prompts versionados\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Output validation implementada\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Fallback strategy funcional\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Content moderation activa\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e PII detection implementada\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Cache configurado\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Retry logic con backoff\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Monitoring \u0026#x26; alerting activos\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Multimodal support (si aplica)\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Token estimation habilitado\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e A/B testing preparado\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Graceful degradation implementada\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eConclusión\u003c/h2\u003e\n\u003cp\u003eGenAI en producción requiere \u003cstrong\u003eingeniería sólida\u003c/strong\u003e, no solo buenas prompts.\u003c/p\u003e\n\u003cp\u003eEstos 15 puntos son la diferencia entre un POC y un sistema production-ready.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cem\u003e¿Implementando GenAI? Consultame: \u003ca href=\"https://mgobeaalcoba.github.io/consulting.html\"\u003eServicios de Consultoría\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"main\",null,{\"className\":\"min-h-screen\",\"children\":[[\"$\",\"$L10\",null,{}],[\"$\",\"$L11\",null,{}],[\"$\",\"article\",null,{\"className\":\"max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 pt-28 pb-20\",\"children\":[[\"$\",\"$L12\",null,{\"href\":\"/blog/\",\"className\":\"inline-flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors mb-8\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],\"Volver al blog\"]}],[\"$\",\"header\",null,{\"className\":\"mb-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-3 mb-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-xs px-2 py-0.5 bg-sky-500/20 text-sky-300 border border-sky-500/30 rounded-full font-medium\",\"children\":\"automation\"}],[\"$\",\"span\",null,{\"className\":\"text-xs px-2 py-0.5 bg-yellow-500/20 text-yellow-300 border border-yellow-500/30 rounded-full\",\"children\":\"⭐ Featured\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-3xl sm:text-4xl font-black text-gray-100 leading-tight mb-4\",\"children\":\"GenAI en Producción: Checklist de 15 puntos antes de deploy\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-400 text-lg leading-relaxed mb-6\",\"children\":\"No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-4 text-sm text-gray-500 pb-6 border-b border-white/10\",\"children\":[[\"$\",\"span\",null,{\"className\":\"flex items-center gap-1.5\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-calendar\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"1cmpym\",{\"d\":\"M8 2v4\"}],[\"$\",\"path\",\"4m81vk\",{\"d\":\"M16 2v4\"}],[\"$\",\"rect\",\"1hopcy\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"8toen8\",{\"d\":\"M3 10h18\"}],\"$undefined\"]}],\"7 de marzo de 2026\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center gap-1.5\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":14,\"height\":14,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-clock\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"path\",\"mmk7yg\",{\"d\":\"M12 6v6l4 2\"}],\"$undefined\"]}],\"12 min\"]}],[\"$\",\"div\",null,{\"className\":\"flex gap-2 flex-wrap\",\"children\":[[\"$\",\"span\",\"genai\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"genai\"]}],[\"$\",\"span\",\"llm\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"llm\"]}],[\"$\",\"span\",\"production\",{\"className\":\"flex items-center gap-1 text-xs text-gray-400\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":10,\"height\":10,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"production\"]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"prose prose-invert prose-sky max-w-none prose-headings:text-gray-100 prose-headings:font-bold prose-p:text-gray-300 prose-p:leading-relaxed prose-a:text-sky-400 prose-a:no-underline hover:prose-a:underline prose-code:text-sky-300 prose-code:bg-sky-500/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:before:content-none prose-code:after:content-none prose-pre:bg-gray-900 prose-pre:border prose-pre:border-white/10 prose-pre:rounded-xl prose-blockquote:border-l-sky-500 prose-blockquote:text-gray-400 prose-strong:text-gray-100 prose-li:text-gray-300 prose-hr:border-white/10 prose-table:border-collapse prose-thead:bg-gray-800/60 prose-th:text-gray-200 prose-th:font-semibold prose-th:border prose-th:border-white/10 prose-th:px-4 prose-th:py-2 prose-td:text-gray-300 prose-td:border prose-td:border-white/10 prose-td:px-4 prose-td:py-2\",\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}],[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-white/10\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-gray-400 text-sm mb-4\",\"children\":[\"Escrito por \",[\"$\",\"span\",null,{\"className\":\"text-sky-400 font-medium\",\"children\":\"Mariano Gobea Alcoba\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\",\"children\":[[\"$\",\"$L12\",null,{\"href\":\"/blog/\",\"className\":\"text-sm text-sky-400 hover:text-sky-300 transition-colors\",\"children\":\"← Otros artículos\"}],[\"$\",\"$L12\",null,{\"href\":\"/consulting/\",\"className\":\"text-sm text-sky-400 hover:text-sky-300 transition-colors\",\"children\":\"Consultoría →\"}]]}]]}]]}],[\"$\",\"$L14\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"GenAI en Producción: Checklist de 15 puntos antes de deploy | Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales.\"}],[\"$\",\"link\",\"4\",{\"rel\":\"author\",\"href\":\"https://mgobeaalcoba.github.io\"}],[\"$\",\"meta\",\"5\",{\"name\":\"author\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"data analytics,technical leader,mercadolibre,mariano gobea alcoba,consultoría tecnológica,automatización,business intelligence,python,machine learning,data engineer,buenos aires\"}],[\"$\",\"meta\",\"7\",{\"name\":\"creator\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"GenAI en Producción: Checklist de 15 puntos antes de deploy\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"13\",{\"property\":\"article:published_time\",\"content\":\"2026-03-08\"}],[\"$\",\"meta\",\"14\",{\"property\":\"article:author\",\"content\":\"Mariano Gobea Alcoba\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:site\",\"content\":\"@MGobeaAlcoba\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:creator\",\"content\":\"@MGobeaAlcoba\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:title\",\"content\":\"GenAI en Producción: Checklist de 15 puntos antes de deploy\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:description\",\"content\":\"No lleves tu modelo de IA a producción sin revisar esto. Lecciones de proyectos reales.\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/icon.png?eced7bd6d4cd2c8e\",\"type\":\"image/png\",\"sizes\":\"512x512\"}]]\n3:null\n"])</script></body></html>