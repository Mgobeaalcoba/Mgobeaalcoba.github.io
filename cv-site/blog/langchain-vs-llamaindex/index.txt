3:I[39275,[],""]
5:I[61343,[],""]
6:I[84080,["223","static/chunks/223-af2330a6fb348319.js","185","static/chunks/app/layout-d6f26fcc1963b964.js"],""]
7:I[45064,["223","static/chunks/223-af2330a6fb348319.js","185","static/chunks/app/layout-d6f26fcc1963b964.js"],"ThemeProvider"]
8:I[78155,["223","static/chunks/223-af2330a6fb348319.js","185","static/chunks/app/layout-d6f26fcc1963b964.js"],"LanguageProvider"]
9:I[74541,["223","static/chunks/223-af2330a6fb348319.js","185","static/chunks/app/layout-d6f26fcc1963b964.js"],"default"]
4:["slug","langchain-vs-llamaindex","d"]
0:["0H7BAbDK5nDkGqgyYYHWC",[[["",{"children":["blog",{"children":[["slug","langchain-vs-llamaindex","d"],{"children":["__PAGE__?{\"slug\":\"langchain-vs-llamaindex\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","langchain-vs-llamaindex","d"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"es","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"href":"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;500&display=swap","rel":"stylesheet"}],["$","meta",null,{"name":"theme-color","content":"#111827"}],["$","meta",null,{"name":"geo.region","content":"AR-C"}],["$","meta",null,{"name":"geo.placename","content":"Buenos Aires"}]]}],["$","body",null,{"children":[["$","link",null,{"rel":"stylesheet","href":"https://assets.calendly.com/assets/external/widget.css"}],["$","$L6",null,{"src":"https://assets.calendly.com/assets/external/widget.js","strategy":"lazyOnload"}],["$","$L6",null,{"src":"https://www.googletagmanager.com/gtag/js?id=G-DG0SLT5RY3","strategy":"afterInteractive"}],["$","$L6",null,{"id":"ga4-init","strategy":"afterInteractive","children":"\n            window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'G-DG0SLT5RY3', {\n              page_path: window.location.pathname,\n              site_section: 'cv',\n              client_name: 'Mariano Gobea Alcoba',\n            });\n          "}],["$","$L7",null,{"children":["$","$L8",null,{"children":["$","$L9",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]}]}]}]]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/cv-site/_next/static/css/f8ac64fc2ba06626.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$La"]]]]]
b:I[53655,["790","static/chunks/790-730599d05686c8ce.js","177","static/chunks/177-ef7799c216a40fc6.js","308","static/chunks/app/blog/%5Bslug%5D/page-76c1c5a125c25d8f.js"],"default"]
c:I[61592,["790","static/chunks/790-730599d05686c8ce.js","177","static/chunks/177-ef7799c216a40fc6.js","308","static/chunks/app/blog/%5Bslug%5D/page-76c1c5a125c25d8f.js"],"default"]
d:I[231,["790","static/chunks/790-730599d05686c8ce.js","177","static/chunks/177-ef7799c216a40fc6.js","308","static/chunks/app/blog/%5Bslug%5D/page-76c1c5a125c25d8f.js"],""]
f:I[65190,["790","static/chunks/790-730599d05686c8ce.js","177","static/chunks/177-ef7799c216a40fc6.js","308","static/chunks/app/blog/%5Bslug%5D/page-76c1c5a125c25d8f.js"],"default"]
e:T15ff,<h2>El Ecosistema de Frameworks GenAI</h2>
<p>En 2024 había 50+ frameworks para GenAI. En 2026, <strong>quedaron dos claros ganadores</strong>:</p>
<ul>
<li><strong>LangChain</strong>: El ecosistema completo</li>
<li><strong>LlamaIndex</strong>: El especialista en RAG</li>
</ul>
<h2>LangChain: El Swiss Army Knife</h2>
<h3>¿Qué hace bien?</h3>
<p><strong>1. Chains de múltiples pasos</strong></p>
<pre><code class="language-python">from langchain.chains import LLMChain, SequentialChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

# Step 1: Analizar email
analyze_prompt = PromptTemplate(
    template="Analiza este email y extrae: {email}",
    input_variables=["email"]
)

# Step 2: Generar respuesta
respond_prompt = PromptTemplate(
    template="Genera respuesta para: {analysis}",
    input_variables=["analysis"]
)

# Chain secuencial
chain = SequentialChain(
    chains=[
        LLMChain(llm=OpenAI(), prompt=analyze_prompt),
        LLMChain(llm=OpenAI(), prompt=respond_prompt)
    ]
)

result = chain.run(email=user_email)
</code></pre>
<p><strong>2. Agents con Tools</strong></p>
<pre><code class="language-python">from langchain.agents import initialize_agent, Tool
from langchain.llms import OpenAI

tools = [
    Tool(
        name="Calculator",
        func=lambda x: eval(x),
        description="Para cálculos matemáticos"
    ),
    Tool(
        name="DatabaseQuery",
        func=query_database,
        description="Para buscar en la base de datos"
    )
]

agent = initialize_agent(tools, OpenAI(), agent="zero-shot-react-description")
agent.run("¿Cuántos usuarios activos tenemos?")
</code></pre>
<p><strong>3. Memory Systems</strong></p>
<pre><code class="language-python">from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory()
chain = LLMChain(llm=OpenAI(), memory=memory)

# Mantiene contexto entre llamadas
chain.run("Mi nombre es Mariano")
chain.run("¿Cuál es mi nombre?")  # "Tu nombre es Mariano"
</code></pre>
<h3>Contras de LangChain</h3>
<ul>
<li>❌ <strong>Abstracción pesada</strong>: A veces más simple hacer directo</li>
<li>❌ <strong>Breaking changes</strong>: Versiones incompatibles frecuentes</li>
<li>❌ <strong>Performance</strong>: Overhead de abstracciones</li>
<li>❌ <strong>Debugging difícil</strong>: Stack traces complejos</li>
</ul>
<h2>LlamaIndex: El Especialista RAG</h2>
<h3>¿Qué hace bien?</h3>
<p><strong>1. Indexing Super Simple</strong></p>
<pre><code class="language-python">from llama_index import VectorStoreIndex, SimpleDirectoryReader

# Cargar documentos
documents = SimpleDirectoryReader('docs/').load_data()

# Crear index (automático)
index = VectorStoreIndex.from_documents(documents)

# Query con contexto
response = index.as_query_engine().query(
    "¿Cómo optimizar queries en BigQuery?"
)
print(response)
</code></pre>
<p><strong>2. Múltiples Index Types</strong></p>
<pre><code class="language-python">from llama_index import (
    VectorStoreIndex,  # Similarity search
    TreeIndex,          # Tree-based retrieval
    KeywordTableIndex,  # Keyword-based
    ListIndex           # Sequential scan
)

# Elegir según caso de uso
index = TreeIndex.from_documents(docs)  # Para docs jerárquicos
</code></pre>
<p><strong>3. Response Synthesis Modes</strong></p>
<pre><code class="language-python"># Modo 1: Compact (rápido, menos contexto)
engine = index.as_query_engine(response_mode="compact")

# Modo 2: Tree Summarize (más contexto, más lento)
engine = index.as_query_engine(response_mode="tree_summarize")

# Modo 3: Simple Concatenate
engine = index.as_query_engine(response_mode="simple_concat")
</code></pre>
<h3>Contras de LlamaIndex</h3>
<ul>
<li>❌ <strong>Solo RAG</strong>: No tiene agents, chains complejos</li>
<li>❌ <strong>Menos flexible</strong>: Opinado en su approach</li>
<li>❌ <strong>Community menor</strong>: Menos integraciones</li>
</ul>
<h2>¿Cuándo Usar Cada Uno?</h2>
<h3>Usa LangChain si:</h3>
<ul>
<li>✅ Necesitás agents con tools</li>
<li>✅ Workflows complejos multi-step</li>
<li>✅ Memory entre conversaciones</li>
<li>✅ Integración con muchos servicios</li>
</ul>
<h3>Usa LlamaIndex si:</h3>
<ul>
<li>✅ Tu caso de uso es 80% RAG</li>
<li>✅ Querés algo simple y que funcione</li>
<li>✅ Performance es crítica</li>
<li>✅ No necesitás agents complejos</li>
</ul>
<h3>Usa Ambos (Hybrid)</h3>
<pre><code class="language-python"># LlamaIndex para RAG
from llama_index import VectorStoreIndex

index = VectorStoreIndex.from_documents(docs)
retriever = index.as_retriever()

# LangChain para agent
from langchain.agents import initialize_agent, Tool

tools = [
    Tool(
        name="KnowledgeBase",
        func=lambda q: retriever.retrieve(q),
        description="Busca en knowledge base"
    )
]

agent = initialize_agent(tools, llm)
</code></pre>
<h2>Mi Setup en Producción</h2>
<p>Para proyectos de consultoría uso:</p>
<ul>
<li><strong>RAG puro</strong>: LlamaIndex (más rápido de implementar)</li>
<li><strong>Chatbots complejos</strong>: LangChain (necesito memory + tools)</li>
<li><strong>MVPs</strong>: LlamaIndex siempre (time to market)</li>
</ul>
<h2>Conclusión</h2>
<p><strong>2026 Recommendation:</strong></p>
<ul>
<li><strong>Default choice:</strong> LlamaIndex (80% de casos)</li>
<li><strong>Complex cases:</strong> LangChain</li>
<li><strong>Best of both:</strong> Hybrid approach</li>
</ul>
<p>Ambos son excelentes. Elegí según tu caso de uso.</p>
<hr>
<p><em>¿Construyendo apps GenAI? <a href="https://calendly.com/mariano-gobea-mercadolibre/30min">Hablemos</a></em></p>
2:["$","main",null,{"className":"min-h-screen","children":[["$","$Lb",null,{}],["$","$Lc",null,{}],["$","article",null,{"className":"max-w-3xl mx-auto px-4 sm:px-6 lg:px-8 pt-28 pb-20","children":[["$","$Ld",null,{"href":"/blog/","className":"inline-flex items-center gap-2 text-sm text-gray-400 hover:text-sky-400 transition-colors mb-8","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":14,"height":14,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"Volver al blog"]}],["$","header",null,{"className":"mb-10","children":[["$","div",null,{"className":"flex flex-wrap items-center gap-3 mb-4","children":[["$","span",null,{"className":"text-xs px-2 py-0.5 bg-sky-500/20 text-sky-300 border border-sky-500/30 rounded-full font-medium","children":"automation"}],["$","span",null,{"className":"text-xs px-2 py-0.5 bg-yellow-500/20 text-yellow-300 border border-yellow-500/30 rounded-full","children":"⭐ Featured"}]]}],["$","h1",null,{"className":"text-3xl sm:text-4xl font-black text-gray-100 leading-tight mb-4","children":"LangChain vs LlamaIndex: ¿Cuál usar para tu app de GenAI?"}],["$","p",null,{"className":"text-gray-400 text-lg leading-relaxed mb-6","children":"Comparativa práctica de los dos frameworks más populares para aplicaciones GenAI."}],["$","div",null,{"className":"flex flex-wrap items-center gap-4 text-sm text-gray-500 pb-6 border-b border-white/10","children":[["$","span",null,{"className":"flex items-center gap-1.5","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":14,"height":14,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-calendar","aria-hidden":"true","children":[["$","path","1cmpym",{"d":"M8 2v4"}],["$","path","4m81vk",{"d":"M16 2v4"}],["$","rect","1hopcy",{"width":"18","height":"18","x":"3","y":"4","rx":"2"}],["$","path","8toen8",{"d":"M3 10h18"}],"$undefined"]}],"11 de abril de 2026"]}],["$","span",null,{"className":"flex items-center gap-1.5","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":14,"height":14,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-clock","aria-hidden":"true","children":[["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],["$","path","mmk7yg",{"d":"M12 6v6l4 2"}],"$undefined"]}],"11 min"]}],["$","div",null,{"className":"flex gap-2 flex-wrap","children":[["$","span","langchain",{"className":"flex items-center gap-1 text-xs text-gray-400","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":10,"height":10,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-tag","aria-hidden":"true","children":[["$","path","vktsd0",{"d":"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"}],["$","circle","kqv944",{"cx":"7.5","cy":"7.5","r":".5","fill":"currentColor"}],"$undefined"]}],"langchain"]}],["$","span","llamaindex",{"className":"flex items-center gap-1 text-xs text-gray-400","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":10,"height":10,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-tag","aria-hidden":"true","children":[["$","path","vktsd0",{"d":"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"}],["$","circle","kqv944",{"cx":"7.5","cy":"7.5","r":".5","fill":"currentColor"}],"$undefined"]}],"llamaindex"]}],["$","span","genai",{"className":"flex items-center gap-1 text-xs text-gray-400","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":10,"height":10,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-tag","aria-hidden":"true","children":[["$","path","vktsd0",{"d":"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"}],["$","circle","kqv944",{"cx":"7.5","cy":"7.5","r":".5","fill":"currentColor"}],"$undefined"]}],"genai"]}]]}]]}]]}],["$","div",null,{"className":"prose prose-invert prose-sky max-w-none prose-headings:text-gray-100 prose-headings:font-bold prose-p:text-gray-300 prose-p:leading-relaxed prose-a:text-sky-400 prose-a:no-underline hover:prose-a:underline prose-code:text-sky-300 prose-code:bg-sky-500/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-pre:bg-gray-900 prose-pre:border prose-pre:border-white/10 prose-blockquote:border-l-sky-500 prose-blockquote:text-gray-400 prose-strong:text-gray-100 prose-li:text-gray-300 prose-hr:border-white/10","dangerouslySetInnerHTML":{"__html":"$e"}}],["$","div",null,{"className":"mt-12 pt-8 border-t border-white/10","children":[["$","p",null,{"className":"text-gray-400 text-sm mb-4","children":["Escrito por ",["$","span",null,{"className":"text-sky-400 font-medium","children":"Mariano Gobea Alcoba"}]]}],["$","div",null,{"className":"flex gap-4","children":[["$","$Ld",null,{"href":"/blog/","className":"text-sm text-sky-400 hover:text-sky-300 transition-colors","children":"← Otros artículos"}],["$","$Ld",null,{"href":"/consulting/","className":"text-sm text-sky-400 hover:text-sky-300 transition-colors","children":"Consultoría →"}]]}]]}]]}],["$","$Lf",null,{}]]}]
a:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"LangChain vs LlamaIndex: ¿Cuál usar para tu app de GenAI? | Mariano Gobea Alcoba"}],["$","meta","3",{"name":"description","content":"Comparativa práctica de los dos frameworks más populares para aplicaciones GenAI."}],["$","link","4",{"rel":"author","href":"https://mgobeaalcoba.github.io"}],["$","meta","5",{"name":"author","content":"Mariano Gobea Alcoba"}],["$","meta","6",{"name":"keywords","content":"data analytics,technical leader,mercadolibre,mariano gobea alcoba,consultoría tecnológica,automatización,business intelligence,python,machine learning,data engineer,buenos aires"}],["$","meta","7",{"name":"creator","content":"Mariano Gobea Alcoba"}],["$","meta","8",{"name":"robots","content":"index, follow"}],["$","meta","9",{"name":"googlebot","content":"index, follow"}],["$","meta","10",{"property":"og:title","content":"LangChain vs LlamaIndex: ¿Cuál usar para tu app de GenAI?"}],["$","meta","11",{"property":"og:description","content":"Comparativa práctica de los dos frameworks más populares para aplicaciones GenAI."}],["$","meta","12",{"property":"og:type","content":"article"}],["$","meta","13",{"property":"article:published_time","content":"2026-04-12"}],["$","meta","14",{"property":"article:author","content":"Mariano Gobea Alcoba"}],["$","meta","15",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","16",{"name":"twitter:site","content":"@MGobeaAlcoba"}],["$","meta","17",{"name":"twitter:creator","content":"@MGobeaAlcoba"}],["$","meta","18",{"name":"twitter:title","content":"LangChain vs LlamaIndex: ¿Cuál usar para tu app de GenAI?"}],["$","meta","19",{"name":"twitter:description","content":"Comparativa práctica de los dos frameworks más populares para aplicaciones GenAI."}],["$","link","20",{"rel":"icon","href":"/cv-site/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
1:null
